Python script to crawl a website, extract all internal links,
and verify their HTTP status codes. It generates a daily report
that lists each link with its response status and timestamp.

The report includes:
- Total number of URLs checked
- Number of failed endpoints (400, 404, 500, or connection errors)
- Full status log of all scanned links

Ideal for website health checks, daily link monitoring, and
broken page detection. Can be run manually or scheduled via
cron/Task Scheduler.
